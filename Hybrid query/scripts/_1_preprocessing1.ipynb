{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45461b47-04ca-4cb8-b48a-d474d3ad908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4db823d-f8b5-4742-ac63-4086ceb8b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from neo4j import GraphDatabase\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29295aa4-0ffa-4f6a-bd4a-9dc71c83824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# Specify the root directory\n",
    "root_dir = './../data/complimentary_raw_data/raw_catalog_data/athena_pt_samples'\n",
    "\n",
    "# List to hold all the file paths\n",
    "file_paths = []\n",
    "\n",
    "# Walk through the directory structure\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if not filename.startswith('.'):\n",
    "            # Construct the full file path and add to the list\n",
    "            file_paths.append(os.path.join(dirpath, filename))\n",
    "\n",
    "# Output the list of file paths\n",
    "print(len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf30215-d2cc-4eb9-80bc-8abd5675a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files:  27%|██▋       | 44/166 [00:28<01:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ./../data/complimentary_raw_data/raw_catalog_data/athena_pt_samples\\drink_flavored_10k.csv: Error tokenizing data. C error: EOF inside string starting at row 2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files:  42%|████▏     | 69/166 [00:50<01:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ./../data/complimentary_raw_data/raw_catalog_data/athena_pt_samples\\hair_extension_10k.csv: Error tokenizing data. C error: EOF inside string starting at row 7511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files:  57%|█████▋    | 95/166 [01:07<00:43,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ./../data/complimentary_raw_data/raw_catalog_data/athena_pt_samples\\medication_10k.csv: Error tokenizing data. C error: EOF inside string starting at row 5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files:  91%|█████████ | 151/166 [01:43<00:06,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ./../data/complimentary_raw_data/raw_catalog_data/athena_pt_samples\\toilet_paper_10k.csv: Error tokenizing data. C error: EOF inside string starting at row 4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files: 100%|██████████| 166/166 [01:53<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               asin active_ingredients additional_product_information  \\\n",
      "0        B07MZCMZNG                NaN                            NaN   \n",
      "1        B07T175PWC                NaN                            NaN   \n",
      "2        B0009RNXNK                NaN                            NaN   \n",
      "3        B06XXTX2H2                NaN                            NaN   \n",
      "4        B00JLVEJ88                NaN                            NaN   \n",
      "...             ...                ...                            ...   \n",
      "1251199  B075MGGBWF                NaN                            NaN   \n",
      "1251200  B01IHFMQ6A                NaN                            NaN   \n",
      "1251201  B008574448                NaN                            NaN   \n",
      "1251202  B07XPDJVZC                NaN                            NaN   \n",
      "1251203  B014SP1PA6                NaN                            NaN   \n",
      "\n",
      "        age_range_description allergen_information      asin.1  \\\n",
      "0                        Baby                  NaN  B07MZCMZNG   \n",
      "1                         Kid                  NaN  B07T175PWC   \n",
      "2                         NaN                  NaN  B0009RNXNK   \n",
      "3                         Kid                  NaN  B06XXTX2H2   \n",
      "4                        Baby                  NaN  B00JLVEJ88   \n",
      "...                       ...                  ...         ...   \n",
      "1251199                   NaN                  NaN  B075MGGBWF   \n",
      "1251200                   NaN                  NaN  B01IHFMQ6A   \n",
      "1251201                   NaN                  NaN  B008574448   \n",
      "1251202                   NaN                  NaN  B07XPDJVZC   \n",
      "1251203                   NaN                  NaN  B014SP1PA6   \n",
      "\n",
      "        battery_capacity_unit  battery_capacity_value  \\\n",
      "0                         NaN                     NaN   \n",
      "1                         NaN                     NaN   \n",
      "2                         NaN                     NaN   \n",
      "3                         NaN                     NaN   \n",
      "4                         NaN                     NaN   \n",
      "...                       ...                     ...   \n",
      "1251199                   NaN                     NaN   \n",
      "1251200                   NaN                     NaN   \n",
      "1251201                   NaN                     NaN   \n",
      "1251202                   NaN                     NaN   \n",
      "1251203                   NaN                     NaN   \n",
      "\n",
      "        battery_cell_composition battery_weight_unit  ...  \\\n",
      "0                            NaN                 NaN  ...   \n",
      "1                            NaN                 NaN  ...   \n",
      "2                            NaN                 NaN  ...   \n",
      "3                            NaN                 NaN  ...   \n",
      "4                            NaN                 NaN  ...   \n",
      "...                          ...                 ...  ...   \n",
      "1251199                      NaN                 NaN  ...   \n",
      "1251200                      NaN                 NaN  ...   \n",
      "1251201                      NaN                 NaN  ...   \n",
      "1251202                      NaN                 NaN  ...   \n",
      "1251203                      NaN                 NaN  ...   \n",
      "\n",
      "         video_capture_resolution watch_movement_type  \\\n",
      "0                             NaN                 NaN   \n",
      "1                             NaN                 NaN   \n",
      "2                             NaN                 NaN   \n",
      "3                             NaN                 NaN   \n",
      "4                             NaN                 NaN   \n",
      "...                           ...                 ...   \n",
      "1251199                       NaN                 NaN   \n",
      "1251200                       NaN                 NaN   \n",
      "1251201                       NaN                 NaN   \n",
      "1251202                       NaN                 NaN   \n",
      "1251203                       NaN                 NaN   \n",
      "\n",
      "        wireless_communication_technology zoom_type shoe_width_unit  \\\n",
      "0                                     NaN       NaN             NaN   \n",
      "1                                     NaN       NaN             NaN   \n",
      "2                                     NaN       NaN             NaN   \n",
      "3                                     NaN       NaN             NaN   \n",
      "4                                     NaN       NaN             NaN   \n",
      "...                                   ...       ...             ...   \n",
      "1251199                               NaN       NaN             NaN   \n",
      "1251200                               NaN       NaN             NaN   \n",
      "1251201                               NaN       NaN             NaN   \n",
      "1251202                               NaN       NaN             NaN   \n",
      "1251203                               NaN       NaN             NaN   \n",
      "\n",
      "        shoe_width_value nut_seed_type  snapshot_day  region_id  \\\n",
      "0                    NaN           NaN    2021-04-30        1.0   \n",
      "1                    NaN           NaN    2021-04-30        1.0   \n",
      "2                    NaN           NaN    2021-04-30        1.0   \n",
      "3                    NaN           NaN    2021-04-30        1.0   \n",
      "4                    NaN           NaN    2021-04-30        1.0   \n",
      "...                  ...           ...           ...        ...   \n",
      "1251199              NaN           NaN    2021-04-30        1.0   \n",
      "1251200              NaN           NaN    2021-04-30        1.0   \n",
      "1251201              NaN           NaN    2021-04-30        1.0   \n",
      "1251202              NaN           NaN    2021-04-30        1.0   \n",
      "1251203              NaN           NaN    2021-04-30        1.0   \n",
      "\n",
      "         marketplace_id  \n",
      "0                   1.0  \n",
      "1                   1.0  \n",
      "2                   1.0  \n",
      "3                   1.0  \n",
      "4                   1.0  \n",
      "...                 ...  \n",
      "1251199             1.0  \n",
      "1251200             1.0  \n",
      "1251201             1.0  \n",
      "1251202             1.0  \n",
      "1251203             1.0  \n",
      "\n",
      "[1251204 rows x 317 columns]\n"
     ]
    }
   ],
   "source": [
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through each file path with a progress bar and read the CSV file into a DataFrame\n",
    "for file_path in tqdm(file_paths, desc=\"Reading CSV files\"):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all the DataFrames into a single DataFrame if there are any valid DataFrames\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    # Output the combined DataFrame\n",
    "    print(combined_df)\n",
    "    # Optionally, save the combined DataFrame to a CSV file\n",
    "    combined_df.to_csv('combined_data.csv', index=False)\n",
    "else:\n",
    "    print(\"No valid CSV files were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611662a4-953d-4c57-95b6-14fbf0b0386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>active_ingredients</th>\n",
       "      <th>additional_product_information</th>\n",
       "      <th>age_range_description</th>\n",
       "      <th>allergen_information</th>\n",
       "      <th>asin.1</th>\n",
       "      <th>battery_capacity_unit</th>\n",
       "      <th>battery_capacity_value</th>\n",
       "      <th>battery_cell_composition</th>\n",
       "      <th>battery_weight_unit</th>\n",
       "      <th>...</th>\n",
       "      <th>video_capture_resolution</th>\n",
       "      <th>watch_movement_type</th>\n",
       "      <th>wireless_communication_technology</th>\n",
       "      <th>zoom_type</th>\n",
       "      <th>shoe_width_unit</th>\n",
       "      <th>shoe_width_value</th>\n",
       "      <th>nut_seed_type</th>\n",
       "      <th>snapshot_day</th>\n",
       "      <th>region_id</th>\n",
       "      <th>marketplace_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07MZCMZNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B07MZCMZNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07T175PWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B07T175PWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0009RNXNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B0009RNXNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B06XXTX2H2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B06XXTX2H2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00JLVEJ88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00JLVEJ88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251199</th>\n",
       "      <td>B075MGGBWF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B075MGGBWF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251200</th>\n",
       "      <td>B01IHFMQ6A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B01IHFMQ6A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251201</th>\n",
       "      <td>B008574448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B008574448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251202</th>\n",
       "      <td>B07XPDJVZC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B07XPDJVZC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251203</th>\n",
       "      <td>B014SP1PA6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B014SP1PA6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251204 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               asin active_ingredients additional_product_information  \\\n",
       "0        B07MZCMZNG                NaN                            NaN   \n",
       "1        B07T175PWC                NaN                            NaN   \n",
       "2        B0009RNXNK                NaN                            NaN   \n",
       "3        B06XXTX2H2                NaN                            NaN   \n",
       "4        B00JLVEJ88                NaN                            NaN   \n",
       "...             ...                ...                            ...   \n",
       "1251199  B075MGGBWF                NaN                            NaN   \n",
       "1251200  B01IHFMQ6A                NaN                            NaN   \n",
       "1251201  B008574448                NaN                            NaN   \n",
       "1251202  B07XPDJVZC                NaN                            NaN   \n",
       "1251203  B014SP1PA6                NaN                            NaN   \n",
       "\n",
       "        age_range_description allergen_information      asin.1  \\\n",
       "0                        Baby                  NaN  B07MZCMZNG   \n",
       "1                         Kid                  NaN  B07T175PWC   \n",
       "2                         NaN                  NaN  B0009RNXNK   \n",
       "3                         Kid                  NaN  B06XXTX2H2   \n",
       "4                        Baby                  NaN  B00JLVEJ88   \n",
       "...                       ...                  ...         ...   \n",
       "1251199                   NaN                  NaN  B075MGGBWF   \n",
       "1251200                   NaN                  NaN  B01IHFMQ6A   \n",
       "1251201                   NaN                  NaN  B008574448   \n",
       "1251202                   NaN                  NaN  B07XPDJVZC   \n",
       "1251203                   NaN                  NaN  B014SP1PA6   \n",
       "\n",
       "        battery_capacity_unit  battery_capacity_value  \\\n",
       "0                         NaN                     NaN   \n",
       "1                         NaN                     NaN   \n",
       "2                         NaN                     NaN   \n",
       "3                         NaN                     NaN   \n",
       "4                         NaN                     NaN   \n",
       "...                       ...                     ...   \n",
       "1251199                   NaN                     NaN   \n",
       "1251200                   NaN                     NaN   \n",
       "1251201                   NaN                     NaN   \n",
       "1251202                   NaN                     NaN   \n",
       "1251203                   NaN                     NaN   \n",
       "\n",
       "        battery_cell_composition battery_weight_unit  ...  \\\n",
       "0                            NaN                 NaN  ...   \n",
       "1                            NaN                 NaN  ...   \n",
       "2                            NaN                 NaN  ...   \n",
       "3                            NaN                 NaN  ...   \n",
       "4                            NaN                 NaN  ...   \n",
       "...                          ...                 ...  ...   \n",
       "1251199                      NaN                 NaN  ...   \n",
       "1251200                      NaN                 NaN  ...   \n",
       "1251201                      NaN                 NaN  ...   \n",
       "1251202                      NaN                 NaN  ...   \n",
       "1251203                      NaN                 NaN  ...   \n",
       "\n",
       "         video_capture_resolution watch_movement_type  \\\n",
       "0                             NaN                 NaN   \n",
       "1                             NaN                 NaN   \n",
       "2                             NaN                 NaN   \n",
       "3                             NaN                 NaN   \n",
       "4                             NaN                 NaN   \n",
       "...                           ...                 ...   \n",
       "1251199                       NaN                 NaN   \n",
       "1251200                       NaN                 NaN   \n",
       "1251201                       NaN                 NaN   \n",
       "1251202                       NaN                 NaN   \n",
       "1251203                       NaN                 NaN   \n",
       "\n",
       "        wireless_communication_technology zoom_type shoe_width_unit  \\\n",
       "0                                     NaN       NaN             NaN   \n",
       "1                                     NaN       NaN             NaN   \n",
       "2                                     NaN       NaN             NaN   \n",
       "3                                     NaN       NaN             NaN   \n",
       "4                                     NaN       NaN             NaN   \n",
       "...                                   ...       ...             ...   \n",
       "1251199                               NaN       NaN             NaN   \n",
       "1251200                               NaN       NaN             NaN   \n",
       "1251201                               NaN       NaN             NaN   \n",
       "1251202                               NaN       NaN             NaN   \n",
       "1251203                               NaN       NaN             NaN   \n",
       "\n",
       "        shoe_width_value nut_seed_type  snapshot_day  region_id  \\\n",
       "0                    NaN           NaN    2021-04-30        1.0   \n",
       "1                    NaN           NaN    2021-04-30        1.0   \n",
       "2                    NaN           NaN    2021-04-30        1.0   \n",
       "3                    NaN           NaN    2021-04-30        1.0   \n",
       "4                    NaN           NaN    2021-04-30        1.0   \n",
       "...                  ...           ...           ...        ...   \n",
       "1251199              NaN           NaN    2021-04-30        1.0   \n",
       "1251200              NaN           NaN    2021-04-30        1.0   \n",
       "1251201              NaN           NaN    2021-04-30        1.0   \n",
       "1251202              NaN           NaN    2021-04-30        1.0   \n",
       "1251203              NaN           NaN    2021-04-30        1.0   \n",
       "\n",
       "         marketplace_id  \n",
       "0                   1.0  \n",
       "1                   1.0  \n",
       "2                   1.0  \n",
       "3                   1.0  \n",
       "4                   1.0  \n",
       "...                 ...  \n",
       "1251199             1.0  \n",
       "1251200             1.0  \n",
       "1251201             1.0  \n",
       "1251202             1.0  \n",
       "1251203             1.0  \n",
       "\n",
       "[1251204 rows x 317 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66c429-c205-483a-b76c-8223e7489385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['input'].nunique())\n",
    "print(df['category'].nunique())\n",
    "print(df['target_scores'].apply(lambda x: str(x)).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff929a-4b21-460d-ae28-8c82bb86d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_df = df[df.duplicated('input', keep='first')]\n",
    "\n",
    "# Print the DataFrame with duplicates\n",
    "print(len(duplicates_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e353f-8fe4-4532-ad8e-30d273fabb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target_scores to string for comparison\n",
    "df['target_scores_str'] = df['target_scores'].apply(lambda x: str(x))\n",
    "\n",
    "# Remove duplicate rows based on all columns including converted target_scores_str\n",
    "df_no_duplicates = df.drop_duplicates(subset=['input', 'category', 'target_scores_str'])\n",
    "\n",
    "# Drop the helper column\n",
    "df_no_duplicates = df_no_duplicates.drop(columns=['target_scores_str'])\n",
    "\n",
    "# Print the DataFrame without duplicates\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097a3a5-f14d-48a1-9f61-af6a227ece57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_no_duplicates\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b1809-5766-483a-a42e-abbb056b40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./../data/data_consolidated.csv')\n",
    "data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e0138-2d58-416c-8587-74596547624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_key_values = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for _, row in data.iterrows():\n",
    "    category = row['category']\n",
    "    score_dict = row['target_scores']\n",
    "    for key, value in score_dict.items():\n",
    "        # Convert the keys to strings before appending\n",
    "        category_key_values[category][key].extend([str(k) for k in value.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832ea19-1818-4707-b007-0e7763329b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4a7a9-df72-49de-8e5c-647c0588a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the nested dictionary\n",
    "data_list = []\n",
    "for category, key_values in category_key_values.items():\n",
    "    for key, values in key_values.items():\n",
    "        data_list.append((category, key, values))\n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "category_key_df = pd.DataFrame(data_list, columns=['category', 'key', 'values'])\n",
    "\n",
    "category_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89734e19-0c27-45f3-9ca0-3f0570d715e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_key_df.to_csv('./../data/category_key_values.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce82f4d-dd9b-4f43-872b-f1369e13648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keys=set()\n",
    "# Iterate through the nested dictionary\n",
    "for category, key_values in category_key_values.items():\n",
    "    for key in key_values.keys():\n",
    "        unique_keys.add(key)\n",
    "\n",
    "# Convert the set to a list and sort it alphabetically\n",
    "unique_keys_list = sorted(list(unique_keys))\n",
    "\n",
    "# Print the sorted unique keys\n",
    "print(unique_keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc5ddb-d1ac-46ab-8712-8687715454fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'n/a' values\n",
    "category_key_df['values'] = category_key_df['values'].apply(lambda x: [v for v in x if v != 'n/a'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989001dc-a6b9-46ae-a21c-62bae6704b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc0a2f-f71b-4e76-857c-4cb44c500961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the frequency of each element in values\n",
    "frequency_dict = defaultdict(lambda: defaultdict(Counter))\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for _, row in category_key_df.iterrows():\n",
    "    category = row['category']\n",
    "    key = row['key']\n",
    "    values = row['values']\n",
    "    frequency_dict[category][key].update(values)\n",
    "\n",
    "# Convert the frequency_dict to a DataFrame for better visualization\n",
    "frequency_data = []\n",
    "for category, keys in frequency_dict.items():\n",
    "    for key, counter in keys.items():\n",
    "        for value, frequency in counter.items():\n",
    "            frequency_data.append((category, key, value, frequency))\n",
    "\n",
    "frequency_df = pd.DataFrame(frequency_data, columns=['category', 'key', 'value', 'frequency'])\n",
    "\n",
    "print(frequency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956e4a0-f7ce-4c06-a77b-1fd92cedb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_df.to_csv('./../data/key_value_frequency.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e36dc4-072f-4cf8-9a32-0451e99e496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = frequency_df.groupby(['category', 'key']).size().reset_index(name='unique_value_count')\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f074f4-bda0-4394-bedf-84a4c3e400a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x5 grid of subplots\n",
    "categories = grouped_df['category'].unique()\n",
    "num_categories = len(categories)\n",
    "num_rows, num_cols = 4, 5  # Define the grid size (4x5)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 16))\n",
    "\n",
    "# Flatten axes for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each category\n",
    "for ax, category in zip(axes, categories):\n",
    "    category_df = grouped_df[grouped_df['category'] == category]\n",
    "    ax.bar(category_df['key'], category_df['unique_value_count'])\n",
    "    ax.set_title(category)\n",
    "    ax.set_xlabel('Key')\n",
    "    ax.set_ylabel('Unique Value Count')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# If there are fewer categories than subplots, remove empty subplots\n",
    "for i in range(len(categories), num_rows * num_cols):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./../plots/category_key_unique_values.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c32eb-37ed-47df-813a-fc363357e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv('./../data/grouped.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38569a28-cb83-4113-855b-b033a6b63b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['context/filter'] = grouped_df.apply(\n",
    "    lambda row: 'context&filter' if row['unique_value_count'] > 10 else 'filter',\n",
    "    axis=1\n",
    ")\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc65d6-a44d-4a21-a1be-a566914e4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the frequency_df with grouped_df to add the 'context/filter' information\n",
    "merged_df = pd.merge(frequency_df, grouped_df[['category', 'key', 'context/filter']], on=['category', 'key'], how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3baf50-97e2-4cec-b61a-da28de60d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify category and key pairs with more than 10 unique values\n",
    "value_counts = merged_df.groupby(['category', 'key']).size().reset_index(name='value_counts')\n",
    "keys_with_more_than_10 = value_counts[value_counts['value_counts'] > 10][['category', 'key']]\n",
    "\n",
    "# Step 2: For keys marked as \"context&filter\", update the \"context/filter\" column\n",
    "def update_context_filter(df, keys_with_more_than_10):\n",
    "    df_updated = df.copy()\n",
    "    for _, row in keys_with_more_than_10.iterrows():\n",
    "        category, key = row['category'], row['key']\n",
    "        mask = (df_updated['category'] == category) & (df_updated['key'] == key)\n",
    "        sub_df = df_updated[mask].copy()\n",
    "        \n",
    "        # Sort by frequency descending\n",
    "        sub_df = sub_df.sort_values(by='frequency', ascending=False)\n",
    "        \n",
    "        # Mark top 10 as 'filter'\n",
    "        top_10_index = sub_df.head(10).index\n",
    "        df_updated.loc[top_10_index, 'context/filter'] = 'filter'\n",
    "        \n",
    "        # Mark the rest as 'context'\n",
    "        rest_index = sub_df.iloc[10:].index\n",
    "        df_updated.loc[rest_index, 'context/filter'] = 'context'\n",
    "    \n",
    "    return df_updated\n",
    "\n",
    "# Apply the update function\n",
    "result_df = update_context_filter(merged_df, keys_with_more_than_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9024b-d745-47f4-92ca-769316cf651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['category']=='Eyewear'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2ccb3-1624-4d15-8e86-2765b710cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./../data/context_filters.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b304a2-45f1-4d90-b7a9-1c913455728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_data = {\n",
    "    'input': [],\n",
    "    'category': [],\n",
    "    'context': [],\n",
    "    'filter': []\n",
    "}\n",
    "template_df = pd.DataFrame(template_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f4b0f-316e-4bc6-89cd-09b59147111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for index, row in data.iterrows():\n",
    "    input_text = row['input']\n",
    "    category = row['category']\n",
    "    target_scores = row['target_scores']\n",
    "    \n",
    "    context_values = [category]\n",
    "    filter_list = []\n",
    "    \n",
    "    for key, values in target_scores.items():\n",
    "        for value, score in values.items():\n",
    "            # Check the context/filter DataFrame for the current key and value\n",
    "            result_mask = (result_df['category'] == category) & (result_df['key'] == key) & (result_df['value'] == value)\n",
    "            if not result_df[result_mask].empty:\n",
    "                context_filter = result_df[result_mask]['context/filter'].values[0]\n",
    "                if context_filter == 'filter':\n",
    "                    filter_list.append(f\"{key}:{value}\")\n",
    "                elif context_filter == 'context':\n",
    "                    context_values.append(value)\n",
    "                elif context_filter == 'context&filter':\n",
    "                    filter_list.append(f\"{key}:{value}\")\n",
    "                    context_values.append(value)\n",
    "    \n",
    "    # Add the information to the list of rows\n",
    "    rows.append({\n",
    "        'input': input_text,\n",
    "        'category': category,\n",
    "        'context': ' '.join(context_values),\n",
    "        'filter': filter_list\n",
    "    })\n",
    "\n",
    "# Convert the list of rows into a DataFrame\n",
    "template_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6f02d-5502-4488-9c7c-8079236048ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_df.to_csv('./../data/template.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a791bcb-f4c2-488d-b9a3-45c44cb348ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_answer_pairs(data, result_df, num_variations=3):\n",
    "    rows = []\n",
    "    for index, row in data.iterrows():\n",
    "        input_text = row['input']\n",
    "        category = row['category']\n",
    "        target_scores = row['target_scores']\n",
    "        \n",
    "        context_values = [category]\n",
    "        filter_dict = {}\n",
    "        \n",
    "        for key, values in target_scores.items():\n",
    "            for value, score in values.items():\n",
    "                # Check the context/filter DataFrame for the current key and value\n",
    "                result_mask = (result_df['category'] == category) & (result_df['key'] == key) & (result_df['value'] == value)\n",
    "                if not result_df[result_mask].empty:\n",
    "                    context_filter = result_df[result_mask]['context/filter'].values[0]\n",
    "                    if context_filter == 'filter':\n",
    "                        filter_dict[key] = value\n",
    "                    elif context_filter == 'context':\n",
    "                        context_values.append(value)\n",
    "                    elif context_filter == 'context&filter':\n",
    "                        filter_dict[key] = value\n",
    "                        context_values.append(value)\n",
    "        \n",
    "        # Original context and filters\n",
    "        rows.append({\n",
    "            'input': input_text,\n",
    "            'category': category,\n",
    "            'context': ' '.join(context_values),\n",
    "            'filter': [f\"{k}:{v}\" for k, v in filter_dict.items()]\n",
    "        })\n",
    "        \n",
    "        # All in context, filter empty\n",
    "        all_in_context = context_values + [v for v in filter_dict.values()]\n",
    "        rows.append({\n",
    "            'input': input_text,\n",
    "            'category': category,\n",
    "            'context': ' '.join(all_in_context),\n",
    "            'filter': []\n",
    "        })\n",
    "        \n",
    "        # Generate multiple variations with some values from filters in context, some omitted, some remain\n",
    "        filter_keys = list(filter_dict.keys())\n",
    "        \n",
    "        for _ in range(num_variations):\n",
    "            random.shuffle(filter_keys)\n",
    "            \n",
    "            # Randomly split into context, filter, and omitted\n",
    "            split_index_context = random.randint(0, len(filter_keys))\n",
    "            split_index_filter = random.randint(0, len(filter_keys) - split_index_context)\n",
    "            \n",
    "            some_in_context = filter_keys[:split_index_context]\n",
    "            some_in_filter = filter_keys[split_index_context:split_index_context + split_index_filter]\n",
    "            some_omitted = filter_keys[split_index_context + split_index_filter:]\n",
    "            \n",
    "            mixed_context = context_values + [filter_dict[k] for k in some_in_context]\n",
    "            mixed_filter = [f\"{k}:{filter_dict[k]}\" for k in some_in_filter]\n",
    "            \n",
    "            rows.append({\n",
    "                'input': input_text,\n",
    "                'category': category,\n",
    "                'context': ' '.join(mixed_context),\n",
    "                'filter': mixed_filter\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6985d5-0523-4a0a-bb88-6a1a9e3d3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2_df = create_query_answer_pairs(data, result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b068cf-a420-43a2-b8af-a6816fc76bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2_df.to_csv(\"./../data/template2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aab1c-b580-436d-a534-3f5ac1eb585f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
